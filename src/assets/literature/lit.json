[
  {
    "title": "Trainable Wavelet Neural Network for Non-Stationary Signals",
    "abstract": "This work introduces a wavelet neural network to learn a filter-bank specialized to fit non-stationary signals and improve interpretability and performance for digital signal processing. The network uses a wavelet transform as the first layer of a neural network where the convolution is a parameterized function of the complex Morlet wavelet. Experimental results, on both simplified data and atmospheric gravity waves, show the network is quick to converge, generalizes well on noisy data, and outperforms standard network architectures.",
    "authors": "Jason Stock, Charles Anderson",
    "pdf": "https://arxiv.org/abs/2205.03355",
    "conference": "AI for Earth and Space Science Workshop at the International Conference on Learning Representations",
    "conf": "ICLR 2022 AI4Earth Workshop (Oral)",
    "logo": "files/trainable_wavelet_1.png"
  },
  {
    "title": " Interpretable Climate Change Modeling with Progressive Cascade Networks",
    "abstract": "Typical deep learning approaches to modeling high-dimensional data often result in complex models that do not easily reveal a new understanding of the data. Research in the deep learning field is very actively pursuing new methods to interpret deep neural networks and to reduce their complexity. An approach is described here that starts with linear models and incrementally adds complexity only as supported by the data. An application is shown in which models that map global temperature and precipitation to years are trained to investigate patterns associated with changes in climate.",
    "authors": "Charles Anderson, Jason Stock, David Anderson",
    "pdf": "https://arxiv.org/abs/2205.06351",
    "conference": "AI for Earth and Space Science Workshop at the International Conference on Learning Representations",
    "conf": "ICLR 2022 AI4Earth Workshop (Poster)",
    "logo": "files/progressive_cascade_nets_1.png"
  },
  {
    "title": "CIRA Guide to Custom Loss Functions for Neural Networks in Environmental Sciences",
    "abstract": "Neural networks are increasingly used in environmental science applications. Furthermore, neural network models are trained by minimizing a loss function, and it is crucial to choose the loss function very carefully for environmental science applications, as it determines what exactly is being optimized. Standard loss functions do not cover all the needs of the environmental sciences, which makes it important for scientists to be able to develop their own custom loss functions so that they can implement many of the classic performance measures already developed in environmental science, including...",
    "authors": "Imme Ebert-Uphoff, Ryan Lagerquist, Kyle Hilburn, Yoonjin Lee, Katherine Haynes, Jason Stock, Christina Kumler, Jebb Q. Stewart",
    "pdf": "https://arxiv.org/abs/2106.09757",
    "conference": "arXiv Preprint 2021",
    "conf": "arXiv Preprint 2021",
    "logo": "files/cira_loss_1.png"
  },
  {
    "title": "Using Machine Learning to Improve Vertical Profiles of Temperature and Moisture for Severe Weather Nowcasting",
    "abstract": "Vertical profiles of temperature and moisture as provided by radiosondes are of paramount importance to forecasting convective activity, yet the National Weather Service radiosonde net- work is spatially coarse and suffers from temporal paucity. Supplementary information generated by numerical weather prediction (NWP) models is invaluableâ€”analysis and forecast profiles are available at a high sampling frequency and horizontal resolution. However, numerical models con- tain inherent errors and inaccuracies, and many of these errors occur near the surface and influence the short-term...",
    "authors": "Jason Stock, John Dandy, Imme Ebert-Uphoff, Chuck Anderson, Jack Dostalek, Lewis Grasso, Jon Zeitler, Harry Weinman",
    "pdf": "https://mountainscholar.org/handle/10217/233704",
    "conference": "AMS 101st Annual Meeting, 20th Conference on Artificial Intelligence for Environmental Science.",
    "conf": "AMS AI 2021 (Oral)",
    "logo": "files/soundings_1.png"
  },
  {
    "title": "Who's a Good Boy? Reinforcing Canine Behavior in Real-Time using Machine Learning",
    "abstract": "In this paper we outline the development methodology for an automatic dog treat dispenser which combines machine learning and embedded hardware to identify and reward dog behaviors in real-time. Using machine learning techniques for training an image classification model we identify three behaviors of our canine companions: 'sit', 'stand', and 'lie down' with up to 92% test accuracy and 39 frames per second. We evaluate a variety of neural network architectures, interpretability methods, model quantization and...",
    "authors": "Jason Stock, Tom Cavey",
    "pdf": "https://arxiv.org/abs/2101.02380",
    "conference": "arXiv Preprint 2021",
    "conf": "arXiv Preprint 2021",
    "logo": "files/whos_a_good_boy_1.png"
  },
  {
    "title": "Strategies for Robust Image Classification",
    "abstract": "In this work we evaluate the impact of digitally altered images on the performance of artificial neural networks. We explore factors that negatively affect the ability of an image classification model to produce consistent and accurate results. A model's ability to classify is negatively influenced by alterations to images as a result of digital abnormalities or changes in the physical environment. The focus of this paper is to discover...",
    "authors": "Jason Stock, Andy Dolan, Tom Cavey",
    "pdf": "https://arxiv.org/abs/2004.03452",
    "conference": "arXiv Preprint 2020",
    "conf": "arXiv Preprint 2020",
    "logo": "files/robust_1.png"
  }
]
